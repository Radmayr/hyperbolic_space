{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-11T13:28:49.095852Z",
     "iopub.status.busy": "2025-05-11T13:28:49.095609Z",
     "iopub.status.idle": "2025-05-11T13:28:54.716010Z",
     "shell.execute_reply": "2025-05-11T13:28:54.715300Z",
     "shell.execute_reply.started": "2025-05-11T13:28:49.095829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/corona-data2/test_dataset.pt\n",
      "/kaggle/input/corona-data2/train_dataset.pt\n",
      "/kaggle/input/data-dop2/Train_mental.pt\n",
      "/kaggle/input/data-dop2/Test_mental.pt\n",
      "/kaggle/input/pncr-metrics/poincare_metrics_runs (2).pkl\n",
      "/kaggle/input/dop-data/Train_amazon.pt\n",
      "/kaggle/input/dop-data/Train_mental.pt\n",
      "/kaggle/input/dop-data/Test_amazon.pt\n",
      "/kaggle/input/dop-data/Test_sentiment.pt\n",
      "/kaggle/input/dop-data/Train_twtter.pt\n",
      "/kaggle/input/dop-data/Test_twtter.pt\n",
      "/kaggle/input/dop-data/Test_mental.pt\n",
      "/kaggle/input/dop-data/Test_financial.pt\n",
      "/kaggle/input/dop-data/Train_financial.pt\n",
      "/kaggle/input/dop-data/Train_sentiment.pt\n",
      "/kaggle/input/datasets-dop3/test_dataset.pt\n",
      "/kaggle/input/datasets-dop3/Train_amazon.pt\n",
      "/kaggle/input/datasets-dop3/Train_mental.pt\n",
      "/kaggle/input/datasets-dop3/Test_amazon.pt\n",
      "/kaggle/input/datasets-dop3/Test_sentiment.pt\n",
      "/kaggle/input/datasets-dop3/Train_twtter.pt\n",
      "/kaggle/input/datasets-dop3/Test_twtter.pt\n",
      "/kaggle/input/datasets-dop3/Test_mental.pt\n",
      "/kaggle/input/datasets-dop3/Test_financial.pt\n",
      "/kaggle/input/datasets-dop3/Train_financial.pt\n",
      "/kaggle/input/datasets-dop3/Train_sentiment.pt\n",
      "/kaggle/input/datasets-dop3/train_dataset.pt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch as th\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T13:28:54.717608Z",
     "iopub.status.busy": "2025-05-11T13:28:54.717279Z",
     "iopub.status.idle": "2025-05-11T13:30:08.225892Z",
     "shell.execute_reply": "2025-05-11T13:30:08.225083Z",
     "shell.execute_reply.started": "2025-05-11T13:28:54.717566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/geoopt/geoopt.git\n",
      "  Cloning https://github.com/geoopt/geoopt.git to /tmp/pip-req-build-lhu12yne\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/geoopt/geoopt.git /tmp/pip-req-build-lhu12yne\n",
      "  Resolved https://github.com/geoopt/geoopt.git to commit eaadc68fcae361778edf078b503ed79e4497c071\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from geoopt==0.5.1) (2.5.1+cu124)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from geoopt==0.5.1) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from geoopt==0.5.1) (1.15.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (4.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.1->geoopt==0.5.1)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.1->geoopt==0.5.1)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.1->geoopt==0.5.1)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.1->geoopt==0.5.1)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.1->geoopt==0.5.1)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.1->geoopt==0.5.1)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.1->geoopt==0.5.1)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.1->geoopt==0.5.1) (1.3.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->geoopt==0.5.1) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->geoopt==0.5.1) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->geoopt==0.5.1) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->geoopt==0.5.1) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->geoopt==0.5.1) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->geoopt==0.5.1) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.1->geoopt==0.5.1) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->geoopt==0.5.1) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->geoopt==0.5.1) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->geoopt==0.5.1) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->geoopt==0.5.1) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->geoopt==0.5.1) (2024.2.0)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: geoopt\n",
      "  Building wheel for geoopt (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for geoopt: filename=geoopt-0.5.1-py3-none-any.whl size=90072 sha256=8ed4a561b9db308ad760d573496b34697ae3dbfa1bbac8fd473bddceeedc0084\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-5r06hgr_/wheels/73/38/55/c6be8a0cd7691d5eb31c63a5452480e4725b74e228929a5593\n",
      "Successfully built geoopt\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, geoopt\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed geoopt-0.5.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/geoopt/geoopt.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T13:30:08.230158Z",
     "iopub.status.busy": "2025-05-11T13:30:08.229480Z",
     "iopub.status.idle": "2025-05-11T13:30:31.400040Z",
     "shell.execute_reply": "2025-05-11T13:30:31.399450Z",
     "shell.execute_reply.started": "2025-05-11T13:30:08.230123Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 13:30:20.513288: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746970220.692920      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746970220.744847      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import math\n",
    "import time\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils as tutils\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import BertModel, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertConfig\n",
    "import geoopt as gt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T13:30:31.402752Z",
     "iopub.status.busy": "2025-05-11T13:30:31.402075Z",
     "iopub.status.idle": "2025-05-11T13:30:31.406003Z",
     "shell.execute_reply": "2025-05-11T13:30:31.405265Z",
     "shell.execute_reply.started": "2025-05-11T13:30:31.402732Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T13:30:31.407068Z",
     "iopub.status.busy": "2025-05-11T13:30:31.406748Z",
     "iopub.status.idle": "2025-05-11T13:30:31.439758Z",
     "shell.execute_reply": "2025-05-11T13:30:31.439025Z",
     "shell.execute_reply.started": "2025-05-11T13:30:31.407051Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T13:30:31.440778Z",
     "iopub.status.busy": "2025-05-11T13:30:31.440518Z",
     "iopub.status.idle": "2025-05-11T13:30:31.455090Z",
     "shell.execute_reply": "2025-05-11T13:30:31.454534Z",
     "shell.execute_reply.started": "2025-05-11T13:30:31.440755Z"
    }
   },
   "outputs": [],
   "source": [
    "class PoincareProbe(nn.Module):\n",
    "    def __init__(\n",
    "        self, device, default_dtype=th.float64, layer_num: int = 10, c: int = -1, \n",
    "        probe_dim = 32\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.default_dtype = default_dtype\n",
    "        self.ball = gt.Stereographic(c)\n",
    "        self.probe_dim = probe_dim\n",
    "        self.layer_num = layer_num\n",
    "\n",
    "        self.bound = 1 / math.sqrt(self.probe_dim)\n",
    "        pos = th.zeros(self.probe_dim).uniform_(-self.bound, self.bound)\n",
    "        neg = th.zeros(self.probe_dim).uniform_(-self.bound, self.bound)\n",
    "        pos = self.ball.expmap0(pos)\n",
    "        neg = self.ball.expmap0(neg)\n",
    "        self.pos = gt.ManifoldParameter(data=pos, manifold=self.ball)\n",
    "        self.neg = gt.ManifoldParameter(data=neg, manifold=self.ball)\n",
    "\n",
    "        self.proj = nn.Parameter(data=th.zeros(768, self.probe_dim))\n",
    "        self.trans = nn.Parameter(data=th.zeros(self.probe_dim, self.probe_dim))\n",
    "        nn.init.uniform_(self.proj, -0.05, 0.05)\n",
    "        nn.init.uniform_(self.trans, -0.05, 0.05)\n",
    "\n",
    "    def forward(self, sequence_output):\n",
    "        transformed = th.matmul(sequence_output, self.proj)\n",
    "        transformed = self.ball.expmap0(transformed)\n",
    "        transformed = self.ball.mobius_matvec(self.trans, transformed)\n",
    "        pos_logits = self.ball.dist(self.neg, transformed).sum(-1)\n",
    "        neg_logits = self.ball.dist(self.pos, transformed).sum(-1)\n",
    "\n",
    "        return th.stack((neg_logits, pos_logits), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T13:30:31.456334Z",
     "iopub.status.busy": "2025-05-11T13:30:31.455867Z",
     "iopub.status.idle": "2025-05-11T13:30:31.473576Z",
     "shell.execute_reply": "2025-05-11T13:30:31.473068Z",
     "shell.execute_reply.started": "2025-05-11T13:30:31.456310Z"
    }
   },
   "outputs": [],
   "source": [
    "class EuclideanProbe(nn.Module):\n",
    "    def __init__(\n",
    "        self, device, default_dtype=th.float32, layer_num: int = 10,\n",
    "        probe_dim = 32\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.default_dtype = default_dtype\n",
    "        self.layer_num = layer_num\n",
    "\n",
    "        self.probe_dim = probe_dim \n",
    "        self.bound = 1 / math.sqrt(self.probe_dim)\n",
    "        self.pos = nn.Parameter(data=th.zeros(self.probe_dim))\n",
    "        self.neg = nn.Parameter(data=th.zeros(self.probe_dim))\n",
    "        nn.init.uniform_(self.pos, -self.bound, self.bound)\n",
    "        nn.init.uniform_(self.neg, -self.bound, self.bound)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.proj = nn.Parameter(data=th.zeros(768, self.probe_dim))\n",
    "        self.trans = nn.Parameter(data=th.zeros(self.probe_dim, self.probe_dim))\n",
    "        nn.init.uniform_(self.proj, -0.05, 0.05)\n",
    "\n",
    "    def forward(self, sequence_output):\n",
    "        transformed = th.matmul(sequence_output, self.proj)\n",
    "        transformed = self.tanh(transformed)\n",
    "        # transformed = th.matmul(transformed, self.trans)\n",
    "        pos_logits = (((self.neg - transformed) ** 2).sum(-1)).sum(-1)\n",
    "        neg_logits = (((self.pos - transformed) ** 2).sum(-1)).sum(-1)\n",
    "        return th.stack((neg_logits, pos_logits), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T13:30:31.474880Z",
     "iopub.status.busy": "2025-05-11T13:30:31.474429Z",
     "iopub.status.idle": "2025-05-11T13:30:31.491109Z",
     "shell.execute_reply": "2025-05-11T13:30:31.490601Z",
     "shell.execute_reply.started": "2025-05-11T13:30:31.474850Z"
    }
   },
   "outputs": [],
   "source": [
    "def Train(\n",
    "    train_data_loader,\n",
    "    probe,\n",
    "    bert,\n",
    "    loss_fct,\n",
    "    optimizer,\n",
    "    dev_data_loader=None,\n",
    "    scheduler=None,\n",
    "):\n",
    "    # Train the probe\n",
    "    probe.train()\n",
    "    train_loss, dev_loss = 0, 0\n",
    "    train_acc, dev_acc = 0, 0\n",
    "    for batch in train_data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        text_input_ids, text_token_type_ids, text_attention_mask, label = (\n",
    "            batch[0],\n",
    "            batch[1],\n",
    "            batch[2],\n",
    "            batch[3],\n",
    "        )\n",
    "        text_input_ids, text_token_type_ids, text_attention_mask, label = (\n",
    "            text_input_ids.to(probe.device),\n",
    "            text_token_type_ids.to(probe.device),\n",
    "            text_attention_mask.to(probe.device),\n",
    "            label.to(probe.device),\n",
    "        )\n",
    "\n",
    "        with th.no_grad():\n",
    "            outputs = bert(\n",
    "                text_input_ids,\n",
    "                attention_mask=text_attention_mask,\n",
    "                token_type_ids=text_token_type_ids,\n",
    "                output_hidden_states=True,\n",
    "            )\n",
    "            hidden_states = outputs[2]\n",
    "            sequence_output = (\n",
    "                hidden_states[probe.layer_num].to(probe.device).to(probe.default_dtype)\n",
    "            )\n",
    "\n",
    "        logits = probe(sequence_output)\n",
    "        l = loss_fct(logits.view(-1, 2), label.view(-1))\n",
    "        train_loss += l.item()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        train_acc += (logits.argmax(-1) == label).sum().item()\n",
    "    train_loss = train_loss / len(train_data_loader.dataset)\n",
    "    train_acc = train_acc / len(train_data_loader.dataset)\n",
    "\n",
    "    if dev_data_loader is not None:\n",
    "        probe.eval()\n",
    "        for batch in dev_data_loader:\n",
    "            text_input_ids, text_token_type_ids, text_attention_mask, label = (\n",
    "                batch[0],\n",
    "                batch[1],\n",
    "                batch[2],\n",
    "                batch[3],\n",
    "            )\n",
    "            text_input_ids, text_token_type_ids, text_attention_mask, label = (\n",
    "                text_input_ids.to(probe.device),\n",
    "                text_token_type_ids.to(probe.device),\n",
    "                text_attention_mask.to(probe.device),\n",
    "                label.to(probe.device),\n",
    "            )\n",
    "\n",
    "            with th.no_grad():\n",
    "                outputs = bert(\n",
    "                    text_input_ids,\n",
    "                    attention_mask=text_attention_mask,\n",
    "                    token_type_ids=text_token_type_ids,\n",
    "                    output_hidden_states=True,\n",
    "                )\n",
    "                hidden_states = outputs[2]\n",
    "                sequence_output = (\n",
    "                    hidden_states[probe.layer_num]\n",
    "                    .to(probe.device)\n",
    "                    .to(probe.default_dtype)\n",
    "                )\n",
    "                logits = probe(sequence_output)\n",
    "\n",
    "                l = loss_fct(logits.view(-1, 2), label.view(-1))\n",
    "                dev_loss += l.item()\n",
    "\n",
    "            dev_acc += (logits.argmax(-1) == label).sum().item()\n",
    "        # Adjust the learning rate\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(dev_loss)\n",
    "\n",
    "        dev_loss = dev_loss / len(dev_data_loader.dataset)\n",
    "        dev_acc = dev_acc / len(dev_data_loader.dataset)\n",
    "\n",
    "    return (\n",
    "        train_loss,\n",
    "        train_acc,\n",
    "        dev_loss,\n",
    "        dev_acc,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T13:30:31.523708Z",
     "iopub.status.busy": "2025-05-11T13:30:31.523200Z",
     "iopub.status.idle": "2025-05-11T13:30:31.536359Z",
     "shell.execute_reply": "2025-05-11T13:30:31.535853Z",
     "shell.execute_reply.started": "2025-05-11T13:30:31.523685Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(test_data_loader, probe, bert, loss_fct):\n",
    "    probe.eval()\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    y_pred = [] \n",
    "    y_true = []\n",
    "    for batch in test_data_loader:\n",
    "        text_input_ids, text_token_type_ids, text_attention_mask, label = (\n",
    "            batch[0],\n",
    "            batch[1],\n",
    "            batch[2],\n",
    "            batch[3],\n",
    "        )\n",
    "        text_input_ids, text_token_type_ids, text_attention_mask, label = (\n",
    "            text_input_ids.to(probe.device),\n",
    "            text_token_type_ids.to(probe.device),\n",
    "            text_attention_mask.to(probe.device),\n",
    "            label.to(probe.device),\n",
    "        )\n",
    "\n",
    "        with th.no_grad():\n",
    "            outputs = bert(\n",
    "                text_input_ids,\n",
    "                attention_mask=text_attention_mask,\n",
    "                token_type_ids=text_token_type_ids,\n",
    "                output_hidden_states=True,\n",
    "            )\n",
    "            hidden_states = outputs[2]\n",
    "            sequence_output = (\n",
    "                hidden_states[probe.layer_num].to(probe.device).to(probe.default_dtype)\n",
    "            )\n",
    "            logits = probe(sequence_output)\n",
    "\n",
    "        l = loss_fct(logits.view(-1, 2), label.view(-1))\n",
    "        loss += l.item()\n",
    "        acc += (logits.argmax(-1) == label).sum().item()\n",
    "        y_pred.extend(list(logits.argmax(-1).cpu().numpy()))\n",
    "        y_true.extend(list(label.cpu().numpy()))\n",
    "        \n",
    "    return l / len(test_data_loader.dataset), acc / len(test_data_loader.dataset), np.array(y_true), np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T13:30:31.538763Z",
     "iopub.status.busy": "2025-05-11T13:30:31.538344Z",
     "iopub.status.idle": "2025-05-11T13:30:31.554018Z",
     "shell.execute_reply": "2025-05-11T13:30:31.553352Z",
     "shell.execute_reply.started": "2025-05-11T13:30:31.538746Z"
    }
   },
   "outputs": [],
   "source": [
    "default_dtype = th.float64\n",
    "th.set_default_dtype(default_dtype)\n",
    "\n",
    "bert_pretrained_file = \"bert-base-uncased\"\n",
    "\n",
    "_layer_num = 10\n",
    "_probe_dim = 32\n",
    "_run_num = 1\n",
    "_epoch_num = 10\n",
    "_batch_size = 32\n",
    "_stop_lr = 5e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T13:30:31.555152Z",
     "iopub.status.busy": "2025-05-11T13:30:31.554750Z",
     "iopub.status.idle": "2025-05-11T13:30:31.567391Z",
     "shell.execute_reply": "2025-05-11T13:30:31.566895Z",
     "shell.execute_reply.started": "2025-05-11T13:30:31.555129Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, device, scheduler):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    \n",
    "    for batch in data_loader:\n",
    "        # input_ids = batch['input_ids'].to(device)\n",
    "        # attention_mask = batch['attention_mask'].to(device)\n",
    "        # labels = batch['label'].to(device)\n",
    "        text_input_ids, text_token_type_ids, text_attention_mask, label = (\n",
    "            batch[0],\n",
    "            batch[1],\n",
    "            batch[2],\n",
    "            batch[3],\n",
    "        )\n",
    "        text_input_ids, text_token_type_ids, text_attention_mask, label = (\n",
    "            text_input_ids.to(device),\n",
    "            text_token_type_ids.to(device),\n",
    "            text_attention_mask.to(device),\n",
    "            label.to(device),\n",
    "        )\n",
    "        outputs = model(\n",
    "            input_ids=text_input_ids,\n",
    "            attention_mask=text_attention_mask,\n",
    "            labels=label\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    return np.mean(losses)\n",
    "\n",
    "def fine_tune(bert, train_loader, device):\n",
    "    EPOCHS = 3\n",
    "    optimizer = optim.Adam(probe.parameters(), lr=0.001)\n",
    "    total_steps = len(train_loader) * EPOCHS\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        train_loss = train_epoch(bert, train_loader, optimizer, device, scheduler)\n",
    "        print(f'Train loss: {train_loss}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T13:30:31.568180Z",
     "iopub.status.busy": "2025-05-11T13:30:31.567965Z",
     "iopub.status.idle": "2025-05-11T13:30:31.586409Z",
     "shell.execute_reply": "2025-05-11T13:30:31.585756Z",
     "shell.execute_reply.started": "2025-05-11T13:30:31.568158Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_evaluate_Poincare(dataset, probe_dim=_probe_dim, layer_num=_layer_num, c=-1):\n",
    "    if __name__ == \"__main__\":\n",
    "    \n",
    "        # device = th.device(\"cpu\")\n",
    "    \n",
    "        if th.cuda.is_available():\n",
    "            device = th.device(\"cuda\")\n",
    "            print(\"GPU доступен:\", th.cuda.get_device_name(0))\n",
    "        else:\n",
    "            device = th.device(\"cpu\")\n",
    "            print(\"GPU недоступен, используется CPU\")\n",
    "    \n",
    "        log_path = 'log'\n",
    "        log_path_models = 'log/model'\n",
    "    \n",
    "        timestr = time.strftime(\"%m%d-%H%M%S\")\n",
    "        if not os.path.exists(log_path):\n",
    "            os.makedirs(log_path)\n",
    "    \n",
    "        train_dataset = th.load(dataset['train'], weights_only=False)\n",
    "        # dev_dataset = th.load(os.path.join(data_path, \"dev_dataset.pt\"))\n",
    "        test_dataset = th.load(dataset['test'], weights_only=False)\n",
    "    \n",
    "        train_data_loader = DataLoader(train_dataset, batch_size=_batch_size, shuffle=True)\n",
    "        # dev_data_loader = DataLoader(dev_dataset, batch_size=_batch_size, shuffle=False)\n",
    "        test_data_loader = DataLoader(test_dataset, batch_size=_batch_size, shuffle=False)\n",
    "    \n",
    "        bert = BertModel.from_pretrained(bert_pretrained_file)\n",
    "        # we are not fine-tuning BERT\n",
    "        for param in bert.parameters():\n",
    "            param.requires_grad = False\n",
    "        bert.to(device)\n",
    "    \n",
    "        log_file = os.path.join(\n",
    "            log_path, dataset['name'] + \"_PUANCARE\" + \"-\" + timestr + \".log\"\n",
    "        )\n",
    "        avg_acc = []\n",
    "        poincare_metric = defaultdict(list)\n",
    "        \n",
    "        for run in range(_run_num):\n",
    "            probe = PoincareProbe(\n",
    "                device=device, default_dtype=default_dtype, layer_num=layer_num,\n",
    "                probe_dim=probe_dim, c=c\n",
    "            )\n",
    "            probe.to(device)\n",
    "    \n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            # optimizer = optim.Adam(probe.parameters(), lr=0.001)\n",
    "            optimizer = gt.optim.RiemannianAdam(\n",
    "                        [\n",
    "                            {\"params\": probe.proj},\n",
    "                            {\"params\": probe.trans},\n",
    "                            {\"params\": probe.pos},\n",
    "                            {\"params\": probe.neg},\n",
    "                        ],\n",
    "                        lr=1e-3,\n",
    "                    )\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=0)\n",
    "    \n",
    "            with open(log_file, \"a\") as f:\n",
    "                f.write(f\"Run: {run + 1}\\n\")\n",
    "            for epoch in tqdm(range(_epoch_num), desc=\"[Epoch]\"):\n",
    "    \n",
    "                start_time = time.time()\n",
    "                train_loss, train_acc, dev_loss, dev_acc = Train(\n",
    "                    train_data_loader,\n",
    "                    probe,\n",
    "                    bert,\n",
    "                    loss_fct,\n",
    "                    optimizer,\n",
    "                    dev_data_loader=test_data_loader,\n",
    "                    scheduler=scheduler,\n",
    "                )\n",
    "    \n",
    "                secs = int(time.time() - start_time)\n",
    "                mins = secs / 60\n",
    "                secs = secs % 60\n",
    "    \n",
    "                test_loss, test_acc, y_true, y_pred = evaluate(test_data_loader, probe, bert, loss_fct)\n",
    "    \n",
    "                with open(log_file, \"a\") as f:\n",
    "                    f.write(\n",
    "                        f\"Epoch: {epoch + 1} | time in {mins:.0f} minutes, {secs:.0f} seconds\\n\"\n",
    "                    )\n",
    "                    f.write(\n",
    "                        f\"\\tTrain Loss: {train_loss:.4f}\\t|\\tTrain Acc: {train_acc * 100:.2f}%\\n\"\n",
    "                    )\n",
    "                    f.write(\n",
    "                        f\"\\tDev Loss: {dev_loss:.4f}\\t|\\tDev Acc: {dev_acc * 100:.2f}%\\n\"\n",
    "                    )\n",
    "                    f.write(\n",
    "                        f\"\\tTest Loss:  {test_loss:.4f}\\t|\\tTest Acc:  {test_acc * 100:.2f}%\\n\"\n",
    "                    )\n",
    "                    f.write(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "                poincare_metric['accuracy'].append(test_acc)\n",
    "                poincare_metric['f1'].append(f1_score(y_true, y_pred))\n",
    "                poincare_metric['precision'].append(precision_score(y_true, y_pred))\n",
    "                poincare_metric['recall'].append(recall_score(y_true, y_pred))\n",
    "                \n",
    "                with open(log_file, \"a\") as f:\n",
    "                    f.write(f\"Avg Acc epoch {epoch}: {test_acc*100:.2f}%\\n\")\n",
    "    \n",
    "                if optimizer.param_groups[0][\"lr\"] < _stop_lr or epoch == _epoch_num - 1:\n",
    "                        break\n",
    "            if not os.path.exists(log_path_models):\n",
    "                os.makedirs(log_path_models)\n",
    "            probe_ckeckpoint = os.path.join(\n",
    "                log_path_models,\n",
    "                dataset['name'] + \"_PUANCARE-\" + \"-\" + timestr + \".pt\",\n",
    "            )\n",
    "            th.save(probe.state_dict(), probe_ckeckpoint)\n",
    "    \n",
    "    return poincare_metric\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:53:58.086915Z",
     "iopub.status.busy": "2025-05-11T16:53:58.086361Z",
     "iopub.status.idle": "2025-05-11T16:53:58.090839Z",
     "shell.execute_reply": "2025-05-11T16:53:58.090261Z",
     "shell.execute_reply.started": "2025-05-11T16:53:58.086892Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    {'name': 'Amazon', \n",
    "    'train': '/kaggle/input/datasets-dop3/Train_amazon.pt', \n",
    "    'test': '/kaggle/input/datasets-dop3/Test_amazon.pt'},\n",
    "    \n",
    "    {'name': 'Financial', \n",
    "    'train': '/kaggle/input/datasets-dop3/Train_financial.pt', \n",
    "    'test': '/kaggle/input/datasets-dop3/Test_financial.pt'}, \n",
    "    \n",
    "    {'name': 'Mental', \n",
    "    'train': '/kaggle/input/datasets-dop3/Train_mental.pt', \n",
    "    'test': '/kaggle/input/datasets-dop3/Test_mental.pt'}, \n",
    "    \n",
    "    {'name': 'Twitter', \n",
    "    'train': '/kaggle/input/datasets-dop3/Train_twtter.pt', \n",
    "    'test': '/kaggle/input/datasets-dop3/Test_twtter.pt'},\n",
    "    \n",
    "    {'name': 'Sentiment', \n",
    "    'train': '/kaggle/input/datasets-dop3/Train_sentiment.pt', \n",
    "    'test': '/kaggle/input/datasets-dop3/Test_sentiment.pt'}, \n",
    "\n",
    "    {'name': 'Corobka Windows', \n",
    "    'train': '/kaggle/input/datasets-dop3/train_dataset.pt', \n",
    "    'test': '/kaggle/input/datasets-dop3/test_dataset.pt'},\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T13:30:31.604528Z",
     "iopub.status.busy": "2025-05-11T13:30:31.604351Z",
     "iopub.status.idle": "2025-05-11T13:30:31.620754Z",
     "shell.execute_reply": "2025-05-11T13:30:31.620064Z",
     "shell.execute_reply.started": "2025-05-11T13:30:31.604514Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/kaggle/input/pncr-metrics/poincare_metrics_runs (2).pkl', 'rb') as f:\n",
    "    poincare_metrics = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-11T11:29:03.357420Z",
     "iopub.status.busy": "2025-05-11T11:29:03.356780Z",
     "iopub.status.idle": "2025-05-11T11:29:03.367576Z",
     "shell.execute_reply": "2025-05-11T11:29:03.366802Z",
     "shell.execute_reply.started": "2025-05-11T11:29:03.357395Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'Amazon': {'run 1': defaultdict(list,\n",
       "                          {'accuracy': [0.866,\n",
       "                            0.8596666666666667,\n",
       "                            0.892,\n",
       "                            0.8893333333333333,\n",
       "                            0.8876666666666667,\n",
       "                            0.8986666666666666,\n",
       "                            0.899,\n",
       "                            0.898,\n",
       "                            0.8973333333333333,\n",
       "                            0.898],\n",
       "                           'f1': [0.8607068607068608,\n",
       "                            0.8719196836020688,\n",
       "                            0.8875000000000001,\n",
       "                            0.8936579115951313,\n",
       "                            0.8927093282394142,\n",
       "                            0.9,\n",
       "                            0.8988988988988987,\n",
       "                            0.8992094861660079,\n",
       "                            0.899214659685864,\n",
       "                            0.8988095238095238],\n",
       "                           'precision': [0.9078947368421053,\n",
       "                            0.8100621820237422,\n",
       "                            0.9383259911894273,\n",
       "                            0.8697007481296758,\n",
       "                            0.8638324091189156,\n",
       "                            0.8988173455978975,\n",
       "                            0.9107505070993914,\n",
       "                            0.8992094861660079,\n",
       "                            0.893368010403121,\n",
       "                            0.9023904382470119],\n",
       "                           'recall': [0.8181818181818182,\n",
       "                            0.9440052700922266,\n",
       "                            0.841897233201581,\n",
       "                            0.9189723320158103,\n",
       "                            0.9235836627140975,\n",
       "                            0.9011857707509882,\n",
       "                            0.8873517786561265,\n",
       "                            0.8992094861660079,\n",
       "                            0.9051383399209486,\n",
       "                            0.8952569169960475]}),\n",
       "              'run 2': defaultdict(list,\n",
       "                          {'accuracy': [0.8053333333333333,\n",
       "                            0.8893333333333333,\n",
       "                            0.8633333333333333,\n",
       "                            0.8846666666666667,\n",
       "                            0.8966666666666666,\n",
       "                            0.899,\n",
       "                            0.9,\n",
       "                            0.8996666666666666,\n",
       "                            0.8996666666666666,\n",
       "                            0.899],\n",
       "                           'f1': [0.7695343330702447,\n",
       "                            0.8922777417261518,\n",
       "                            0.8750761730652042,\n",
       "                            0.8910579345088162,\n",
       "                            0.8941256830601093,\n",
       "                            0.8981512605042017,\n",
       "                            0.898580121703854,\n",
       "                            0.9000332115576221,\n",
       "                            0.9000332115576221,\n",
       "                            0.8997684419450876],\n",
       "                           'precision': [0.9596456692913385,\n",
       "                            0.879156010230179,\n",
       "                            0.8140589569160998,\n",
       "                            0.853437876960193,\n",
       "                            0.9283687943262411,\n",
       "                            0.9169526424159231,\n",
       "                            0.9229166666666667,\n",
       "                            0.9075686537173476,\n",
       "                            0.9075686537173476,\n",
       "                            0.9036544850498339],\n",
       "                           'recall': [0.642292490118577,\n",
       "                            0.9057971014492754,\n",
       "                            0.9459815546772069,\n",
       "                            0.9321475625823452,\n",
       "                            0.8623188405797102,\n",
       "                            0.8801054018445322,\n",
       "                            0.8754940711462451,\n",
       "                            0.8926218708827405,\n",
       "                            0.8926218708827405,\n",
       "                            0.8959156785243741]}),\n",
       "              'run 3': defaultdict(list,\n",
       "                          {'accuracy': [0.8683333333333333,\n",
       "                            0.8813333333333333,\n",
       "                            0.8903333333333333,\n",
       "                            0.8993333333333333,\n",
       "                            0.898,\n",
       "                            0.897,\n",
       "                            0.8993333333333333,\n",
       "                            0.8993333333333333,\n",
       "                            0.8993333333333333,\n",
       "                            0.8986666666666666],\n",
       "                           'f1': [0.8737615851709811,\n",
       "                            0.88712745719721,\n",
       "                            0.8939051918735892,\n",
       "                            0.899734395750332,\n",
       "                            0.897863818424566,\n",
       "                            0.8955021981738247,\n",
       "                            0.8987256874580818,\n",
       "                            0.8990641711229946,\n",
       "                            0.899131596526386,\n",
       "                            0.8985313751668892],\n",
       "                           'precision': [0.8485412787088765,\n",
       "                            0.8551344743276283,\n",
       "                            0.8755527479469362,\n",
       "                            0.9069611780455153,\n",
       "                            0.9100135317997293,\n",
       "                            0.9200833912439194,\n",
       "                            0.9153005464480874,\n",
       "                            0.912483039348711,\n",
       "                            0.9119241192411924,\n",
       "                            0.9106901217861976],\n",
       "                           'recall': [0.9005270092226614,\n",
       "                            0.9216073781291173,\n",
       "                            0.9130434782608695,\n",
       "                            0.8926218708827405,\n",
       "                            0.886034255599473,\n",
       "                            0.8722002635046113,\n",
       "                            0.8827404479578392,\n",
       "                            0.886034255599473,\n",
       "                            0.8866930171277997,\n",
       "                            0.8866930171277997]}),\n",
       "              'run 4': defaultdict(list,\n",
       "                          {'accuracy': [0.8663333333333333,\n",
       "                            0.883,\n",
       "                            0.9,\n",
       "                            0.871,\n",
       "                            0.909,\n",
       "                            0.9033333333333333,\n",
       "                            0.909,\n",
       "                            0.9086666666666666,\n",
       "                            0.908,\n",
       "                            0.9076666666666666],\n",
       "                           'f1': [0.8591499824376537,\n",
       "                            0.8873917228103946,\n",
       "                            0.9018324607329844,\n",
       "                            0.8821917808219178,\n",
       "                            0.9084813945692256,\n",
       "                            0.9010914051841746,\n",
       "                            0.9078014184397163,\n",
       "                            0.908176943699732,\n",
       "                            0.9078156312625252,\n",
       "                            0.9075742409075741],\n",
       "                           'precision': [0.9202407825432656,\n",
       "                            0.8649155722326454,\n",
       "                            0.8959687906371911,\n",
       "                            0.8200339558573854,\n",
       "                            0.9249146757679181,\n",
       "                            0.9342291371994342,\n",
       "                            0.9313929313929314,\n",
       "                            0.9242837653478854,\n",
       "                            0.9207317073170732,\n",
       "                            0.9195402298850575],\n",
       "                           'recall': [0.80566534914361,\n",
       "                            0.9110671936758893,\n",
       "                            0.9077733860342556,\n",
       "                            0.9545454545454546,\n",
       "                            0.8926218708827405,\n",
       "                            0.8702239789196311,\n",
       "                            0.8853754940711462,\n",
       "                            0.8926218708827405,\n",
       "                            0.8952569169960475,\n",
       "                            0.8959156785243741]}),\n",
       "              'run 5': defaultdict(list,\n",
       "                          {'accuracy': [0.8573333333333333,\n",
       "                            0.849,\n",
       "                            0.8893333333333333,\n",
       "                            0.8923333333333333,\n",
       "                            0.893,\n",
       "                            0.893,\n",
       "                            0.896,\n",
       "                            0.895,\n",
       "                            0.8956666666666667,\n",
       "                            0.895],\n",
       "                           'f1': [0.8667496886674969,\n",
       "                            0.8635953026196928,\n",
       "                            0.8912901113294041,\n",
       "                            0.89171974522293,\n",
       "                            0.8921733288545516,\n",
       "                            0.8963513077171457,\n",
       "                            0.8956521739130436,\n",
       "                            0.8952444296641171,\n",
       "                            0.8954924874791318,\n",
       "                            0.8952444296641171],\n",
       "                           'precision': [0.8217237308146399,\n",
       "                            0.7953410981697171,\n",
       "                            0.8860677083333334,\n",
       "                            0.9078498293515358,\n",
       "                            0.910212474297464,\n",
       "                            0.8790373654211526,\n",
       "                            0.9096467391304348,\n",
       "                            0.9039623908663532,\n",
       "                            0.9079214624238321,\n",
       "                            0.9039623908663532],\n",
       "                           'recall': [0.9169960474308301,\n",
       "                            0.9446640316205533,\n",
       "                            0.8965744400527009,\n",
       "                            0.8761528326745718,\n",
       "                            0.8748353096179183,\n",
       "                            0.9143610013175231,\n",
       "                            0.8820816864295126,\n",
       "                            0.8866930171277997,\n",
       "                            0.883399209486166,\n",
       "                            0.8866930171277997]})},\n",
       "             'Financial': {'run 1': defaultdict(list,\n",
       "                          {'accuracy': [0.7810526315789473,\n",
       "                            0.7589473684210526,\n",
       "                            0.8242105263157895,\n",
       "                            0.8368421052631579,\n",
       "                            0.8347368421052631,\n",
       "                            0.8315789473684211,\n",
       "                            0.8347368421052631,\n",
       "                            0.8347368421052631,\n",
       "                            0.8336842105263158],\n",
       "                           'f1': [0.8537271448663853,\n",
       "                            0.8488448844884489,\n",
       "                            0.8752800597460793,\n",
       "                            0.8784313725490196,\n",
       "                            0.8806083650190114,\n",
       "                            0.8789712556732224,\n",
       "                            0.8807896735003796,\n",
       "                            0.8807896735003796,\n",
       "                            0.8801213960546281],\n",
       "                           'precision': [0.7903645833333334,\n",
       "                            0.7468060394889663,\n",
       "                            0.8554744525547445,\n",
       "                            0.9017713365539453,\n",
       "                            0.875945537065053,\n",
       "                            0.8697604790419161,\n",
       "                            0.8748114630467572,\n",
       "                            0.8748114630467572,\n",
       "                            0.8734939759036144],\n",
       "                           'recall': [0.9281345565749235,\n",
       "                            0.9831804281345565,\n",
       "                            0.8960244648318043,\n",
       "                            0.8562691131498471,\n",
       "                            0.8853211009174312,\n",
       "                            0.8883792048929664,\n",
       "                            0.8868501529051988,\n",
       "                            0.8868501529051988,\n",
       "                            0.8868501529051988]}),\n",
       "              'run 2': defaultdict(list,\n",
       "                          {'accuracy': [0.8178947368421052,\n",
       "                            0.7978947368421052,\n",
       "                            0.8231578947368421,\n",
       "                            0.8431578947368421,\n",
       "                            0.8421052631578947,\n",
       "                            0.8410526315789474,\n",
       "                            0.8442105263157895,\n",
       "                            0.8442105263157895,\n",
       "                            0.8421052631578947,\n",
       "                            0.8431578947368421],\n",
       "                           'f1': [0.8738147337709702,\n",
       "                            0.8372881355932202,\n",
       "                            0.8651685393258427,\n",
       "                            0.8863463005339436,\n",
       "                            0.885145482388974,\n",
       "                            0.8853454821564161,\n",
       "                            0.8865030674846627,\n",
       "                            0.8868501529051988,\n",
       "                            0.8854961832061069,\n",
       "                            0.8859984697781178],\n",
       "                           'precision': [0.8354253835425384,\n",
       "                            0.9391634980988594,\n",
       "                            0.910472972972973,\n",
       "                            0.8843226788432268,\n",
       "                            0.8865030674846626,\n",
       "                            0.8793363499245852,\n",
       "                            0.8892307692307693,\n",
       "                            0.8868501529051988,\n",
       "                            0.8841463414634146,\n",
       "                            0.886676875957121],\n",
       "                           'recall': [0.9159021406727829,\n",
       "                            0.7553516819571865,\n",
       "                            0.8241590214067278,\n",
       "                            0.8883792048929664,\n",
       "                            0.8837920489296636,\n",
       "                            0.8914373088685015,\n",
       "                            0.8837920489296636,\n",
       "                            0.8868501529051988,\n",
       "                            0.8868501529051988,\n",
       "                            0.8853211009174312]}),\n",
       "              'run 3': defaultdict(list,\n",
       "                          {'accuracy': [0.7642105263157895,\n",
       "                            0.7957894736842105,\n",
       "                            0.8052631578947368,\n",
       "                            0.82,\n",
       "                            0.8242105263157895,\n",
       "                            0.82,\n",
       "                            0.828421052631579,\n",
       "                            0.8263157894736842,\n",
       "                            0.8242105263157895,\n",
       "                            0.8294736842105264],\n",
       "                           'f1': [0.8130217028380635,\n",
       "                            0.8639551192145861,\n",
       "                            0.8484848484848485,\n",
       "                            0.8717179294823707,\n",
       "                            0.8745304282494365,\n",
       "                            0.8726731198808637,\n",
       "                            0.8752869166029075,\n",
       "                            0.8745247148288973,\n",
       "                            0.8728103579588729,\n",
       "                            0.8755760368663594],\n",
       "                           'precision': [0.8952205882352942,\n",
       "                            0.7979274611398963,\n",
       "                            0.9135802469135802,\n",
       "                            0.8556701030927835,\n",
       "                            0.8596750369276218,\n",
       "                            0.8505079825834543,\n",
       "                            0.8759571209800919,\n",
       "                            0.869894099848714,\n",
       "                            0.8694992412746586,\n",
       "                            0.8796296296296297],\n",
       "                           'recall': [0.7446483180428135,\n",
       "                            0.9418960244648318,\n",
       "                            0.7920489296636085,\n",
       "                            0.8883792048929664,\n",
       "                            0.8899082568807339,\n",
       "                            0.8960244648318043,\n",
       "                            0.8746177370030581,\n",
       "                            0.8792048929663608,\n",
       "                            0.8761467889908257,\n",
       "                            0.8715596330275229]}),\n",
       "              'run 4': defaultdict(list,\n",
       "                          {'accuracy': [0.7736842105263158,\n",
       "                            0.8263157894736842,\n",
       "                            0.8189473684210526,\n",
       "                            0.8263157894736842,\n",
       "                            0.8431578947368421,\n",
       "                            0.8336842105263158,\n",
       "                            0.8326315789473684,\n",
       "                            0.8336842105263158,\n",
       "                            0.8336842105263158,\n",
       "                            0.8336842105263158],\n",
       "                           'f1': [0.8179508890770534,\n",
       "                            0.8739495798319328,\n",
       "                            0.8700906344410877,\n",
       "                            0.8672566371681416,\n",
       "                            0.888722927557879,\n",
       "                            0.8813813813813814,\n",
       "                            0.8798185941043083,\n",
       "                            0.8795731707317073,\n",
       "                            0.8795731707317073,\n",
       "                            0.8795731707317073],\n",
       "                           'precision': [0.9165085388994307,\n",
       "                            0.8732824427480916,\n",
       "                            0.8597014925373134,\n",
       "                            0.9151103565365025,\n",
       "                            0.8686131386861314,\n",
       "                            0.8657817109144543,\n",
       "                            0.8699551569506726,\n",
       "                            0.8768996960486323,\n",
       "                            0.8768996960486323,\n",
       "                            0.8768996960486323],\n",
       "                           'recall': [0.7385321100917431,\n",
       "                            0.8746177370030581,\n",
       "                            0.8807339449541285,\n",
       "                            0.8241590214067278,\n",
       "                            0.9097859327217125,\n",
       "                            0.8975535168195719,\n",
       "                            0.8899082568807339,\n",
       "                            0.882262996941896,\n",
       "                            0.882262996941896,\n",
       "                            0.882262996941896]}),\n",
       "              'run 5': defaultdict(list,\n",
       "                          {'accuracy': [0.7873684210526316,\n",
       "                            0.7042105263157895,\n",
       "                            0.8221052631578948,\n",
       "                            0.8263157894736842,\n",
       "                            0.8410526315789474,\n",
       "                            0.8273684210526315,\n",
       "                            0.84,\n",
       "                            0.84,\n",
       "                            0.84],\n",
       "                           'f1': [0.8614540466392319,\n",
       "                            0.7300672430355428,\n",
       "                            0.8745360059391241,\n",
       "                            0.8773234200743494,\n",
       "                            0.8808208366219415,\n",
       "                            0.8757575757575758,\n",
       "                            0.8832565284178187,\n",
       "                            0.8832565284178187,\n",
       "                            0.8832565284178187],\n",
       "                           'precision': [0.7810945273631841,\n",
       "                            0.9819121447028424,\n",
       "                            0.84992784992785,\n",
       "                            0.85383502170767,\n",
       "                            0.9102773246329527,\n",
       "                            0.8678678678678678,\n",
       "                            0.8873456790123457,\n",
       "                            0.8873456790123457,\n",
       "                            0.8873456790123457],\n",
       "                           'recall': [0.9602446483180428,\n",
       "                            0.581039755351682,\n",
       "                            0.900611620795107,\n",
       "                            0.9021406727828746,\n",
       "                            0.8532110091743119,\n",
       "                            0.8837920489296636,\n",
       "                            0.8792048929663608,\n",
       "                            0.8792048929663608,\n",
       "                            0.8792048929663608]})},\n",
       "             'Twitter': {'run 1': defaultdict(list,\n",
       "                          {'accuracy': [0.7440022579734689,\n",
       "                            0.5709850409257691,\n",
       "                            0.7885972339825007,\n",
       "                            0.790008467400508,\n",
       "                            0.7792830934236523,\n",
       "                            0.7880327406152978,\n",
       "                            0.7883149872988993,\n",
       "                            0.7880327406152978,\n",
       "                            0.7877504939316963],\n",
       "                           'f1': [0.7735330836454432,\n",
       "                            0.3001841620626151,\n",
       "                            0.7861832714815873,\n",
       "                            0.8000000000000002,\n",
       "                            0.7644578313253011,\n",
       "                            0.7922544951590594,\n",
       "                            0.7903856903297932,\n",
       "                            0.7886293273290177,\n",
       "                            0.7885264341957254],\n",
       "                           'precision': [0.7144833948339483,\n",
       "                            0.9731343283582089,\n",
       "                            0.826530612244898,\n",
       "                            0.7902283590015932,\n",
       "                            0.8556979096426163,\n",
       "                            0.8053993250843644,\n",
       "                            0.8121769098219415,\n",
       "                            0.8164335664335665,\n",
       "                            0.8155904595695171],\n",
       "                           'recall': [0.8432226456178552,\n",
       "                            0.17746325530756668,\n",
       "                            0.7495917256396298,\n",
       "                            0.8100163309744148,\n",
       "                            0.6908002177463255,\n",
       "                            0.7795318454001089,\n",
       "                            0.7697332607512248,\n",
       "                            0.7626565051714752,\n",
       "                            0.7632008709853021]})}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poincare_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T13:30:31.621606Z",
     "iopub.status.busy": "2025-05-11T13:30:31.621416Z",
     "iopub.status.idle": "2025-05-11T16:48:14.115423Z",
     "shell.execute_reply": "2025-05-11T16:48:14.114823Z",
     "shell.execute_reply.started": "2025-05-11T13:30:31.621572Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter\n",
      "\n",
      "run 1\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0b4e8a0fb2445991ffae326c7a6a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ffdd75b1f44d6881cbc54d4b526ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  70%|███████   | 7/10 [20:07<08:37, 172.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 2\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  70%|███████   | 7/10 [20:02<08:35, 171.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 3\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  90%|█████████ | 9/10 [25:01<02:46, 166.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 4\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  90%|█████████ | 9/10 [25:02<02:46, 166.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 5\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  90%|█████████ | 9/10 [25:02<02:46, 166.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "\n",
      "run 1\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  80%|████████  | 8/10 [05:49<01:27, 43.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 2\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  90%|█████████ | 9/10 [06:26<00:42, 42.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 3\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  70%|███████   | 7/10 [05:09<02:12, 44.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 4\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  90%|█████████ | 9/10 [06:26<00:42, 42.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 5\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  80%|████████  | 8/10 [05:47<01:26, 43.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corobka Windows\n",
      "\n",
      "run 1\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  70%|███████   | 7/10 [09:07<03:54, 78.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 2\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  80%|████████  | 8/10 [10:15<02:33, 76.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 3\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  80%|████████  | 8/10 [10:16<02:34, 77.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 4\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  90%|█████████ | 9/10 [11:25<01:16, 76.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 5\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  90%|█████████ | 9/10 [11:25<01:16, 76.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# poincare_metrics = defaultdict(dict)\n",
    "for dataset in datasets:\n",
    "    print(dataset['name'] + '\\n')\n",
    "    for run in range(1, 6):\n",
    "        print(f'run {run}' + '\\n')\n",
    "        poincare_metrics[dataset['name']][f'run {run}'] = train_evaluate_Poincare(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:48:14.116713Z",
     "iopub.status.busy": "2025-05-11T16:48:14.116414Z",
     "iopub.status.idle": "2025-05-11T16:48:14.122129Z",
     "shell.execute_reply": "2025-05-11T16:48:14.121557Z",
     "shell.execute_reply.started": "2025-05-11T16:48:14.116688Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('poincare_metrics_runs.pkl', 'wb') as f:\n",
    "    pickle.dump(poincare_metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T10:55:59.358450Z",
     "iopub.status.busy": "2025-05-09T10:55:59.358206Z",
     "iopub.status.idle": "2025-05-09T11:04:41.345847Z",
     "shell.execute_reply": "2025-05-09T11:04:41.345040Z",
     "shell.execute_reply.started": "2025-05-09T10:55:59.358431Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Financial\n",
      "\n",
      "probe_dim 4\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  86%|████████▌ | 6/7 [02:09<00:21, 21.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probe_dim 8\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  86%|████████▌ | 6/7 [02:09<00:21, 21.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probe_dim 16\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  86%|████████▌ | 6/7 [02:09<00:21, 21.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probe_dim 64\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  86%|████████▌ | 6/7 [02:09<00:21, 21.52s/it]\n"
     ]
    }
   ],
   "source": [
    "# Меняем размерность пробы \n",
    "poincare_metrics = defaultdict(dict)\n",
    "for dataset in datasets:\n",
    "    print(dataset['name'] + '\\n')\n",
    "    for probe_dim in [4, 8, 16, 64]:\n",
    "        print(f'probe_dim {probe_dim}' + '\\n')\n",
    "        poincare_metrics[dataset['name']][f'probe_dim {probe_dim}'] = train_evaluate_Poincare(dataset, probe_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T08:24:19.721821Z",
     "iopub.status.busy": "2025-05-09T08:24:19.721162Z",
     "iopub.status.idle": "2025-05-09T08:35:09.239793Z",
     "shell.execute_reply": "2025-05-09T08:35:09.238960Z",
     "shell.execute_reply.started": "2025-05-09T08:24:19.721797Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Financial\n",
      "\n",
      "c -0.1\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  86%|████████▌ | 6/7 [02:08<00:21, 21.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c -0.5\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  86%|████████▌ | 6/7 [02:08<00:21, 21.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c -1\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  86%|████████▌ | 6/7 [02:08<00:21, 21.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c -2\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  86%|████████▌ | 6/7 [02:09<00:21, 21.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c -5\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch]:  86%|████████▌ | 6/7 [02:09<00:21, 21.56s/it]\n"
     ]
    }
   ],
   "source": [
    "# Меняем размерность пробы \n",
    "poincare_metrics = defaultdict(dict)\n",
    "for dataset in datasets:\n",
    "    print(dataset['name'] + '\\n')\n",
    "    for c in [-0.1, -0.5, -1, -2, -5]:\n",
    "        print(f'c {c}' + '\\n')\n",
    "        poincare_metrics[dataset['name']][f'c {c}'] = train_evaluate_Poincare(dataset, c=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T07:38:03.475863Z",
     "iopub.status.busy": "2025-05-09T07:38:03.475195Z",
     "iopub.status.idle": "2025-05-09T07:38:03.479623Z",
     "shell.execute_reply": "2025-05-09T07:38:03.479094Z",
     "shell.execute_reply.started": "2025-05-09T07:38:03.475837Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('poincare_metrics_metrics_probes.pkl', 'wb') as f:\n",
    "    pickle.dump(poincare_metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:53:28.753857Z",
     "iopub.status.busy": "2025-05-11T16:53:28.753551Z",
     "iopub.status.idle": "2025-05-11T16:53:28.765763Z",
     "shell.execute_reply": "2025-05-11T16:53:28.765090Z",
     "shell.execute_reply.started": "2025-05-11T16:53:28.753838Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_evaluate_Euclide(dataset, probe_dim=_probe_dim, layer_num=_layer_num):\n",
    "    if __name__ == \"__main__\":\n",
    "    \n",
    "        # device = th.device(\"cpu\")\n",
    "    \n",
    "        if th.cuda.is_available():\n",
    "            device = th.device(\"cuda\")\n",
    "            print(\"GPU доступен:\", th.cuda.get_device_name(0))\n",
    "        else:\n",
    "            device = th.device(\"cpu\")\n",
    "            print(\"GPU недоступен, используется CPU\")\n",
    "    \n",
    "        log_path = 'log'\n",
    "        log_path_models = 'log/model'\n",
    "        \n",
    "        timestr = time.strftime(\"%m%d-%H%M%S\")\n",
    "        if not os.path.exists(log_path):\n",
    "            os.makedirs(log_path)\n",
    "    \n",
    "        train_dataset = th.load(dataset['train'], weights_only=False)\n",
    "        # dev_dataset = th.load(os.path.join(data_path, \"dev_dataset.pt\"))\n",
    "        test_dataset = th.load(dataset['test'], weights_only=False)\n",
    "    \n",
    "        train_data_loader = DataLoader(train_dataset, batch_size=_batch_size, shuffle=True)\n",
    "        # dev_data_loader = DataLoader(dev_dataset, batch_size=_batch_size, shuffle=False)\n",
    "        test_data_loader = DataLoader(test_dataset, batch_size=_batch_size, shuffle=False)\n",
    "    \n",
    "        bert = BertModel.from_pretrained(bert_pretrained_file)\n",
    "        # we are not fine-tuning BERT\n",
    "        for param in bert.parameters():\n",
    "            param.requires_grad = False\n",
    "        bert.to(device)\n",
    "    \n",
    "        log_file = os.path.join(\n",
    "            log_path, dataset['name'] + \"_Eucleude\" + \"-\" + timestr + \".log\"\n",
    "        )\n",
    "        avg_acc = []\n",
    "        euclid_metric = defaultdict(list)\n",
    "    \n",
    "        for run in tqdm(range(_run_num), desc=\"[Run]\"):\n",
    "            probe = EuclideanProbe(\n",
    "                device=device, default_dtype=default_dtype, layer_num=layer_num,\n",
    "                probe_dim=probe_dim\n",
    "            )\n",
    "            probe.to(device)\n",
    "    \n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(probe.parameters(), lr=0.001)\n",
    "            \n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=0)\n",
    "    \n",
    "            with open(log_file, \"a\") as f:\n",
    "                f.write(f\"Run: {run + 1}\\n\")\n",
    "            for epoch in tqdm(range(_epoch_num), desc=\"[Epoch]\"):\n",
    "    \n",
    "                start_time = time.time()\n",
    "                train_loss, train_acc, dev_loss, dev_acc = Train(\n",
    "                    train_data_loader,\n",
    "                    probe,\n",
    "                    bert,\n",
    "                    loss_fct,\n",
    "                    optimizer,\n",
    "                    dev_data_loader=test_data_loader,\n",
    "                    scheduler=scheduler,\n",
    "                )\n",
    "    \n",
    "                secs = int(time.time() - start_time)\n",
    "                mins = secs / 60\n",
    "                secs = secs % 60\n",
    "    \n",
    "                test_loss, test_acc, y_true, y_pred = evaluate(test_data_loader, probe, bert, loss_fct)\n",
    "    \n",
    "                with open(log_file, \"a\") as f:\n",
    "                    f.write(\n",
    "                        f\"Epoch: {epoch + 1} | time in {mins:.0f} minutes, {secs:.0f} seconds\\n\"\n",
    "                    )\n",
    "                    f.write(\n",
    "                        f\"\\tTrain Loss: {train_loss:.4f}\\t|\\tTrain Acc: {train_acc * 100:.2f}%\\n\"\n",
    "                    )\n",
    "                    f.write(\n",
    "                        f\"\\tDev Loss: {dev_loss:.4f}\\t|\\tDev Acc: {dev_acc * 100:.2f}%\\n\"\n",
    "                    )\n",
    "                    f.write(\n",
    "                        f\"\\tTest Loss:  {test_loss:.4f}\\t|\\tTest Acc:  {test_acc * 100:.2f}%\\n\"\n",
    "                    )\n",
    "                    f.write(\"-\" * 50 + \"\\n\")\n",
    "    \n",
    "                euclid_metric['accuracy'].append(test_acc)\n",
    "                euclid_metric['f1'].append(f1_score(y_true, y_pred))\n",
    "                euclid_metric['precision'].append(precision_score(y_true, y_pred))\n",
    "                euclid_metric['recall'].append(recall_score(y_true, y_pred))\n",
    "                with open(log_file, \"a\") as f:\n",
    "                    f.write(f\"Avg Acc epoch {epoch}: {test_acc*100:.2f}%\\n\")\n",
    "                    \n",
    "                if optimizer.param_groups[0][\"lr\"] < _stop_lr or epoch == _epoch_num - 1:\n",
    "                    break\n",
    "            \n",
    "            if not os.path.exists(log_path_models):\n",
    "                os.makedirs(log_path_models)\n",
    "            probe_ckeckpoint = os.path.join(\n",
    "                log_path_models,\n",
    "                dataset['name'] + \"_Eucleude\" + \"-run-\" + str(run) + \"-\" + timestr + \".pt\",\n",
    "            )\n",
    "            th.save(probe.state_dict(), probe_ckeckpoint)\n",
    "    \n",
    "    return euclid_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T16:56:52.243357Z",
     "iopub.status.busy": "2025-05-11T16:56:52.242759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 1\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Run]:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[Epoch]:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch]:  10%|█         | 1/10 [02:34<23:07, 154.15s/it]\u001b[A\n",
      "[Epoch]:  20%|██        | 2/10 [05:08<20:32, 154.10s/it]\u001b[A\n",
      "[Epoch]:  30%|███       | 3/10 [07:42<17:58, 154.07s/it]\u001b[A\n",
      "[Epoch]:  40%|████      | 4/10 [10:16<15:24, 154.04s/it]\u001b[A\n",
      "[Epoch]:  50%|█████     | 5/10 [12:50<12:50, 154.03s/it]\u001b[A\n",
      "[Epoch]:  60%|██████    | 6/10 [15:24<10:16, 154.01s/it]\u001b[A\n",
      "[Epoch]:  70%|███████   | 7/10 [17:58<07:41, 154.00s/it]\u001b[A\n",
      "[Epoch]:  80%|████████  | 8/10 [20:32<05:07, 153.99s/it]\u001b[A\n",
      "[Epoch]:  90%|█████████ | 9/10 [25:40<02:51, 171.13s/it]\u001b[A\n",
      "[Run]: 100%|██████████| 1/1 [25:40<00:00, 1540.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 2\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Run]:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[Epoch]:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch]:  10%|█         | 1/10 [02:34<23:06, 154.01s/it]\u001b[A\n",
      "[Epoch]:  20%|██        | 2/10 [05:08<20:32, 154.01s/it]\u001b[A\n",
      "[Epoch]:  30%|███       | 3/10 [07:42<17:57, 154.00s/it]\u001b[A\n",
      "[Epoch]:  40%|████      | 4/10 [10:15<15:23, 153.98s/it]\u001b[A\n",
      "[Epoch]:  50%|█████     | 5/10 [12:49<12:49, 153.99s/it]\u001b[A\n",
      "[Epoch]:  60%|██████    | 6/10 [15:23<10:15, 153.99s/it]\u001b[A\n",
      "[Epoch]:  70%|███████   | 7/10 [17:57<07:41, 153.99s/it]\u001b[A\n",
      "[Epoch]:  80%|████████  | 8/10 [20:31<05:07, 153.99s/it]\u001b[A\n",
      "[Epoch]:  90%|█████████ | 9/10 [25:39<02:51, 171.07s/it]\u001b[A\n",
      "[Run]: 100%|██████████| 1/1 [25:39<00:00, 1539.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 3\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Run]:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[Epoch]:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch]:  10%|█         | 1/10 [02:33<23:05, 153.99s/it]\u001b[A\n",
      "[Epoch]:  20%|██        | 2/10 [05:08<20:32, 154.00s/it]\u001b[A\n",
      "[Epoch]:  30%|███       | 3/10 [07:42<17:58, 154.00s/it]\u001b[A\n",
      "[Epoch]:  40%|████      | 4/10 [10:15<15:23, 153.99s/it]\u001b[A\n",
      "[Epoch]:  50%|█████     | 5/10 [12:50<12:50, 154.00s/it]\u001b[A\n",
      "[Epoch]:  60%|██████    | 6/10 [15:24<10:16, 154.01s/it]\u001b[A\n",
      "[Epoch]:  70%|███████   | 7/10 [17:58<07:42, 154.01s/it]\u001b[A\n",
      "[Epoch]:  80%|████████  | 8/10 [20:31<05:07, 153.97s/it]\u001b[A\n",
      "[Epoch]:  90%|█████████ | 9/10 [25:39<02:51, 171.09s/it]\u001b[A\n",
      "[Run]: 100%|██████████| 1/1 [25:39<00:00, 1539.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 4\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Run]:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[Epoch]:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch]:  10%|█         | 1/10 [02:33<23:05, 153.98s/it]\u001b[A\n",
      "[Epoch]:  20%|██        | 2/10 [05:07<20:32, 154.00s/it]\u001b[A\n",
      "[Epoch]:  30%|███       | 3/10 [07:42<17:58, 154.01s/it]\u001b[A\n",
      "[Epoch]:  40%|████      | 4/10 [10:16<15:24, 154.01s/it]\u001b[A\n",
      "[Epoch]:  50%|█████     | 5/10 [12:50<12:50, 154.01s/it]\u001b[A\n",
      "[Epoch]:  60%|██████    | 6/10 [15:24<10:16, 154.01s/it]\u001b[A\n",
      "[Epoch]:  70%|███████   | 7/10 [17:58<07:42, 154.00s/it]\u001b[A\n",
      "[Epoch]:  80%|████████  | 8/10 [20:31<05:07, 153.99s/it]\u001b[A\n",
      "[Epoch]:  90%|█████████ | 9/10 [25:39<02:51, 171.10s/it]\u001b[A\n",
      "[Run]: 100%|██████████| 1/1 [25:39<00:00, 1539.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 5\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Run]:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[Epoch]:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch]:  10%|█         | 1/10 [02:33<23:05, 153.96s/it]\u001b[A\n",
      "[Epoch]:  20%|██        | 2/10 [05:07<20:31, 153.96s/it]\u001b[A\n",
      "[Epoch]:  30%|███       | 3/10 [07:41<17:57, 153.96s/it]\u001b[A\n",
      "[Epoch]:  40%|████      | 4/10 [10:15<15:23, 153.98s/it]\u001b[A\n",
      "[Epoch]:  50%|█████     | 5/10 [12:49<12:49, 153.98s/it]\u001b[A\n",
      "[Epoch]:  60%|██████    | 6/10 [15:23<10:15, 153.98s/it]\u001b[A\n",
      "[Epoch]:  70%|███████   | 7/10 [17:57<07:41, 153.99s/it]\u001b[A\n",
      "[Epoch]:  80%|████████  | 8/10 [20:31<05:07, 153.99s/it]\u001b[A\n",
      "[Epoch]:  90%|█████████ | 9/10 [25:39<02:51, 171.10s/it]\u001b[A\n",
      "[Run]: 100%|██████████| 1/1 [25:39<00:00, 1539.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 1\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Run]:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[Epoch]:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch]:  10%|█         | 1/10 [00:19<02:52, 19.18s/it]\u001b[A\n",
      "[Epoch]:  20%|██        | 2/10 [00:38<02:33, 19.17s/it]\u001b[A\n",
      "[Epoch]:  30%|███       | 3/10 [00:57<02:14, 19.16s/it]\u001b[A\n",
      "[Epoch]:  40%|████      | 4/10 [01:16<01:54, 19.17s/it]\u001b[A\n",
      "[Epoch]:  50%|█████     | 5/10 [01:35<01:35, 19.17s/it]\u001b[A\n",
      "[Epoch]:  60%|██████    | 6/10 [01:55<01:16, 19.17s/it]\u001b[A\n",
      "[Epoch]:  70%|███████   | 7/10 [02:14<00:57, 19.18s/it]\u001b[A\n",
      "[Epoch]:  80%|████████  | 8/10 [02:33<00:38, 19.17s/it]\u001b[A\n",
      "[Epoch]:  90%|█████████ | 9/10 [03:11<00:21, 21.30s/it]\u001b[A\n",
      "[Run]: 100%|██████████| 1/1 [03:11<00:00, 191.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 2\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Run]:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[Epoch]:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch]:  10%|█         | 1/10 [00:19<02:52, 19.16s/it]\u001b[A\n",
      "[Epoch]:  20%|██        | 2/10 [00:38<02:33, 19.16s/it]\u001b[A\n",
      "[Epoch]:  30%|███       | 3/10 [00:57<02:14, 19.16s/it]\u001b[A\n",
      "[Epoch]:  40%|████      | 4/10 [01:16<01:54, 19.16s/it]\u001b[A\n",
      "[Epoch]:  50%|█████     | 5/10 [01:35<01:35, 19.16s/it]\u001b[A\n",
      "[Epoch]:  60%|██████    | 6/10 [01:54<01:16, 19.17s/it]\u001b[A\n",
      "[Epoch]:  70%|███████   | 7/10 [02:14<00:57, 19.16s/it]\u001b[A\n",
      "[Epoch]:  80%|████████  | 8/10 [02:33<00:38, 19.16s/it]\u001b[A\n",
      "[Epoch]:  90%|█████████ | 9/10 [03:11<00:21, 21.29s/it]\u001b[A\n",
      "[Run]: 100%|██████████| 1/1 [03:11<00:00, 191.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 3\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Run]:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[Epoch]:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch]:  10%|█         | 1/10 [00:19<02:52, 19.18s/it]\u001b[A\n",
      "[Epoch]:  20%|██        | 2/10 [00:38<02:33, 19.17s/it]\u001b[A\n",
      "[Epoch]:  30%|███       | 3/10 [00:57<02:14, 19.17s/it]\u001b[A\n",
      "[Epoch]:  40%|████      | 4/10 [01:16<01:55, 19.17s/it]\u001b[A\n",
      "[Epoch]:  50%|█████     | 5/10 [01:35<01:35, 19.17s/it]\u001b[A\n",
      "[Epoch]:  60%|██████    | 6/10 [01:55<01:16, 19.17s/it]\u001b[A\n",
      "[Epoch]:  70%|███████   | 7/10 [02:14<00:57, 19.17s/it]\u001b[A\n",
      "[Epoch]:  80%|████████  | 8/10 [02:33<00:38, 19.17s/it]\u001b[A\n",
      "[Epoch]:  90%|█████████ | 9/10 [03:11<00:21, 21.30s/it]\u001b[A\n",
      "[Run]: 100%|██████████| 1/1 [03:11<00:00, 191.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 4\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Run]:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[Epoch]:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch]:  10%|█         | 1/10 [00:19<02:52, 19.16s/it]\u001b[A\n",
      "[Epoch]:  20%|██        | 2/10 [00:38<02:33, 19.16s/it]\u001b[A\n",
      "[Epoch]:  30%|███       | 3/10 [00:57<02:14, 19.17s/it]\u001b[A\n",
      "[Epoch]:  40%|████      | 4/10 [01:16<01:54, 19.17s/it]\u001b[A\n",
      "[Epoch]:  50%|█████     | 5/10 [01:35<01:35, 19.17s/it]\u001b[A\n",
      "[Epoch]:  60%|██████    | 6/10 [01:55<01:16, 19.17s/it]\u001b[A\n",
      "[Epoch]:  70%|███████   | 7/10 [02:14<00:57, 19.17s/it]\u001b[A\n",
      "[Epoch]:  80%|████████  | 8/10 [02:33<00:38, 19.17s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "euclide_metrics = defaultdict(dict)\n",
    "for dataset in datasets:\n",
    "    for run in range(1, 6):\n",
    "        print(f'run {run}' + '\\n')\n",
    "        euclide_metrics[dataset['name']][f'run {run}'] = train_evaluate_Euclide(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('euclide_metrics_runs.pkl', 'wb') as f:\n",
    "    pickle.dump(euclide_metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T07:38:36.385627Z",
     "iopub.status.busy": "2025-05-09T07:38:36.385334Z",
     "iopub.status.idle": "2025-05-09T07:47:02.309857Z",
     "shell.execute_reply": "2025-05-09T07:47:02.309224Z",
     "shell.execute_reply.started": "2025-05-09T07:38:36.385604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probe_dim 4\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Run]:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[Epoch]:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch]:  14%|█▍        | 1/7 [00:17<01:47, 17.96s/it]\u001b[A\n",
      "[Epoch]:  29%|██▊       | 2/7 [00:35<01:29, 17.85s/it]\u001b[A\n",
      "[Epoch]:  43%|████▎     | 3/7 [00:53<01:11, 17.81s/it]\u001b[A\n",
      "[Epoch]:  57%|█████▋    | 4/7 [01:11<00:53, 17.82s/it]\u001b[A\n",
      "[Epoch]:  71%|███████▏  | 5/7 [01:29<00:35, 17.86s/it]\u001b[A\n",
      "[Epoch]:  86%|████████▌ | 6/7 [02:05<00:20, 20.87s/it]\u001b[A\n",
      "[Run]: 100%|██████████| 1/1 [02:05<00:00, 125.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probe_dim 8\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Run]:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[Epoch]:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch]:  14%|█▍        | 1/7 [00:17<01:47, 17.96s/it]\u001b[A\n",
      "[Epoch]:  29%|██▊       | 2/7 [00:35<01:29, 17.98s/it]\u001b[A\n",
      "[Epoch]:  43%|████▎     | 3/7 [00:53<01:11, 17.98s/it]\u001b[A\n",
      "[Epoch]:  57%|█████▋    | 4/7 [01:11<00:53, 17.97s/it]\u001b[A\n",
      "[Epoch]:  71%|███████▏  | 5/7 [01:29<00:35, 17.97s/it]\u001b[A\n",
      "[Epoch]:  86%|████████▌ | 6/7 [02:05<00:20, 20.95s/it]\u001b[A\n",
      "[Run]: 100%|██████████| 1/1 [02:05<00:00, 125.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probe_dim 16\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Run]:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[Epoch]:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch]:  14%|█▍        | 1/7 [00:17<01:47, 17.95s/it]\u001b[A\n",
      "[Epoch]:  29%|██▊       | 2/7 [00:35<01:29, 17.94s/it]\u001b[A\n",
      "[Epoch]:  43%|████▎     | 3/7 [00:53<01:11, 17.95s/it]\u001b[A\n",
      "[Epoch]:  57%|█████▋    | 4/7 [01:11<00:53, 17.95s/it]\u001b[A\n",
      "[Epoch]:  71%|███████▏  | 5/7 [01:29<00:35, 17.95s/it]\u001b[A\n",
      "[Epoch]:  86%|████████▌ | 6/7 [02:05<00:20, 20.94s/it]\u001b[A\n",
      "[Run]: 100%|██████████| 1/1 [02:05<00:00, 125.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probe_dim 64\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Run]:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[Epoch]:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch]:  14%|█▍        | 1/7 [00:17<01:47, 17.95s/it]\u001b[A\n",
      "[Epoch]:  29%|██▊       | 2/7 [00:35<01:29, 17.95s/it]\u001b[A\n",
      "[Epoch]:  43%|████▎     | 3/7 [00:53<01:11, 17.95s/it]\u001b[A\n",
      "[Epoch]:  57%|█████▋    | 4/7 [01:11<00:53, 17.95s/it]\u001b[A\n",
      "[Epoch]:  71%|███████▏  | 5/7 [01:29<00:35, 17.95s/it]\u001b[A\n",
      "[Epoch]:  86%|████████▌ | 6/7 [02:05<00:20, 20.94s/it]\u001b[A\n",
      "[Run]: 100%|██████████| 1/1 [02:05<00:00, 125.65s/it]\n"
     ]
    }
   ],
   "source": [
    "euclide_metrics = defaultdict(dict)\n",
    "for dataset in datasets:\n",
    "    for probe_dim in [4, 8, 16, 64]:\n",
    "        print(f'probe_dim {probe_dim}' + '\\n')\n",
    "        euclide_metrics[dataset['name']][f'probe_dim {probe_dim}'] = train_evaluate_Euclide(dataset, probe_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T11:15:28.362923Z",
     "iopub.status.busy": "2025-05-09T11:15:28.362619Z",
     "iopub.status.idle": "2025-05-09T11:34:19.797932Z",
     "shell.execute_reply": "2025-05-09T11:34:19.797305Z",
     "shell.execute_reply.started": "2025-05-09T11:15:28.362902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Financial\n",
      "\n",
      "layer_num 3\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Run]:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[Epoch]:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch]:  14%|█▍        | 1/7 [00:17<01:46, 17.83s/it]\u001b[A\n",
      "[Epoch]:  29%|██▊       | 2/7 [00:35<01:29, 17.81s/it]\u001b[A\n",
      "[Epoch]:  43%|████▎     | 3/7 [00:53<01:11, 17.81s/it]\u001b[A\n",
      "[Epoch]:  57%|█████▋    | 4/7 [01:11<00:53, 17.81s/it]\u001b[A\n",
      "[Epoch]:  71%|███████▏  | 5/7 [01:29<00:35, 17.81s/it]\u001b[A\n",
      "[Epoch]:  86%|████████▌ | 6/7 [02:04<00:20, 20.78s/it]\u001b[A\n",
      "[Run]: 100%|██████████| 1/1 [02:04<00:00, 124.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_num 4\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Run]:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[Epoch]:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch]:  14%|█▍        | 1/7 [00:17<01:47, 17.84s/it]\u001b[A\n",
      "[Epoch]:  29%|██▊       | 2/7 [00:35<01:29, 17.82s/it]\u001b[A\n",
      "[Epoch]:  43%|████▎     | 3/7 [00:53<01:11, 17.81s/it]\u001b[A\n",
      "[Epoch]:  57%|█████▋    | 4/7 [01:11<00:53, 17.81s/it]\u001b[A\n",
      "[Epoch]:  71%|███████▏  | 5/7 [01:29<00:35, 17.81s/it]\u001b[A\n",
      "[Epoch]:  86%|████████▌ | 6/7 [02:04<00:20, 20.78s/it]\u001b[A\n",
      "[Run]: 100%|██████████| 1/1 [02:04<00:00, 124.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_num 5\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Run]:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[Epoch]:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch]:  14%|█▍        | 1/7 [00:17<01:46, 17.82s/it]\u001b[A\n",
      "[Epoch]:  29%|██▊       | 2/7 [00:35<01:29, 17.81s/it]\u001b[A\n",
      "[Epoch]:  43%|████▎     | 3/7 [00:53<01:11, 17.81s/it]\u001b[A\n",
      "[Epoch]:  57%|█████▋    | 4/7 [01:11<00:53, 17.81s/it]\u001b[A\n",
      "[Epoch]:  71%|███████▏  | 5/7 [01:29<00:35, 17.81s/it]\u001b[A\n",
      "[Epoch]:  86%|████████▌ | 6/7 [02:04<00:20, 20.77s/it]\u001b[A\n",
      "[Run]: 100%|██████████| 1/1 [02:04<00:00, 124.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_num 6\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Run]:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[Epoch]:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch]:  14%|█▍        | 1/7 [00:17<01:47, 17.84s/it]\u001b[A\n",
      "[Epoch]:  29%|██▊       | 2/7 [00:35<01:29, 17.81s/it]\u001b[A\n",
      "[Epoch]:  43%|████▎     | 3/7 [00:53<01:11, 17.80s/it]\u001b[A\n",
      "[Epoch]:  57%|█████▋    | 4/7 [01:11<00:53, 17.80s/it]\u001b[A\n",
      "[Epoch]:  71%|███████▏  | 5/7 [01:29<00:35, 17.81s/it]\u001b[A\n",
      "[Epoch]:  86%|████████▌ | 6/7 [02:04<00:20, 20.77s/it]\u001b[A\n",
      "[Run]: 100%|██████████| 1/1 [02:04<00:00, 124.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_num 7\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Run]:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[Epoch]:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch]:  14%|█▍        | 1/7 [00:17<01:47, 17.85s/it]\u001b[A\n",
      "[Epoch]:  29%|██▊       | 2/7 [00:35<01:29, 17.82s/it]\u001b[A\n",
      "[Epoch]:  43%|████▎     | 3/7 [00:53<01:11, 17.80s/it]\u001b[A\n",
      "[Epoch]:  57%|█████▋    | 4/7 [01:11<00:53, 17.80s/it]\u001b[A\n",
      "[Epoch]:  71%|███████▏  | 5/7 [01:29<00:35, 17.80s/it]\u001b[A\n",
      "[Epoch]:  86%|████████▌ | 6/7 [02:04<00:20, 20.77s/it]\u001b[A\n",
      "[Run]: 100%|██████████| 1/1 [02:04<00:00, 124.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_num 8\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Run]:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[Epoch]:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch]:  14%|█▍        | 1/7 [00:17<01:46, 17.79s/it]\u001b[A\n",
      "[Epoch]:  29%|██▊       | 2/7 [00:35<01:28, 17.79s/it]\u001b[A\n",
      "[Epoch]:  43%|████▎     | 3/7 [00:53<01:11, 17.79s/it]\u001b[A\n",
      "[Epoch]:  57%|█████▋    | 4/7 [01:11<00:53, 17.79s/it]\u001b[A\n",
      "[Epoch]:  71%|███████▏  | 5/7 [01:28<00:35, 17.79s/it]\u001b[A\n",
      "[Epoch]:  86%|████████▌ | 6/7 [02:04<00:20, 20.76s/it]\u001b[A\n",
      "[Run]: 100%|██████████| 1/1 [02:04<00:00, 124.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_num 9\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Run]:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[Epoch]:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch]:  14%|█▍        | 1/7 [00:17<01:46, 17.81s/it]\u001b[A\n",
      "[Epoch]:  29%|██▊       | 2/7 [00:35<01:28, 17.80s/it]\u001b[A\n",
      "[Epoch]:  43%|████▎     | 3/7 [00:53<01:11, 17.80s/it]\u001b[A\n",
      "[Epoch]:  57%|█████▋    | 4/7 [01:11<00:53, 17.80s/it]\u001b[A\n",
      "[Epoch]:  71%|███████▏  | 5/7 [01:28<00:35, 17.80s/it]\u001b[A\n",
      "[Epoch]:  86%|████████▌ | 6/7 [02:04<00:20, 20.76s/it]\u001b[A\n",
      "[Run]: 100%|██████████| 1/1 [02:04<00:00, 124.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_num 10\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Run]:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[Epoch]:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch]:  14%|█▍        | 1/7 [00:17<01:46, 17.79s/it]\u001b[A\n",
      "[Epoch]:  29%|██▊       | 2/7 [00:35<01:28, 17.79s/it]\u001b[A\n",
      "[Epoch]:  43%|████▎     | 3/7 [00:53<01:11, 17.79s/it]\u001b[A\n",
      "[Epoch]:  57%|█████▋    | 4/7 [01:11<00:53, 17.79s/it]\u001b[A\n",
      "[Epoch]:  71%|███████▏  | 5/7 [01:28<00:35, 17.79s/it]\u001b[A\n",
      "[Epoch]:  86%|████████▌ | 6/7 [02:04<00:20, 20.76s/it]\u001b[A\n",
      "[Run]: 100%|██████████| 1/1 [02:04<00:00, 124.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_num 11\n",
      "\n",
      "GPU доступен: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Run]:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "[Epoch]:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "[Epoch]:  14%|█▍        | 1/7 [00:17<01:47, 17.86s/it]\u001b[A\n",
      "[Epoch]:  29%|██▊       | 2/7 [00:35<01:29, 17.82s/it]\u001b[A\n",
      "[Epoch]:  43%|████▎     | 3/7 [00:53<01:11, 17.81s/it]\u001b[A\n",
      "[Epoch]:  57%|█████▋    | 4/7 [01:11<00:53, 17.80s/it]\u001b[A\n",
      "[Epoch]:  71%|███████▏  | 5/7 [01:29<00:35, 17.80s/it]\u001b[A\n",
      "[Epoch]:  86%|████████▌ | 6/7 [02:04<00:20, 20.77s/it]\u001b[A\n",
      "[Run]: 100%|██████████| 1/1 [02:04<00:00, 124.65s/it]\n"
     ]
    }
   ],
   "source": [
    "# Меняем размерность пробы \n",
    "euclide_metrics = defaultdict(dict)\n",
    "for dataset in datasets:\n",
    "    print(dataset['name'] + '\\n')\n",
    "    for layer_num in range(3, 12):\n",
    "        print(f'layer_num {layer_num}' + '\\n')\n",
    "        euclide_metrics[dataset['name']][f'layer_num {layer_num}'] = train_evaluate_Euclide(dataset, layer_num=layer_num)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7271623,
     "sourceId": 11595699,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7283758,
     "sourceId": 11612174,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7284697,
     "sourceId": 11613406,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7376694,
     "sourceId": 11750330,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7388820,
     "sourceId": 11769364,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
